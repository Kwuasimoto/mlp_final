{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDI 1002 Final Term Project Report\n",
    "\n",
    "Members:\n",
    "\n",
    "Leon Quadros - 200532151 </br>\n",
    "Leon.Quadros@GeorgianCollege.ca\n",
    "\n",
    "Thomas Shank - 200346862</br>\n",
    "Thomas.Shank@GeorgianCollege.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "A broad overview of image classification involves assigning labels to images based on different categories, such as animals, vehicles or objects. Various patterns of pixels are decoded to numerical values and classified. These classifications of numerical vectors help models generalize input images and predict their content. However, this process is computationally exhaustive as it requires many steps including image processing and bounding box placement.\n",
    "\n",
    "The challenges of image classification are complex. These include lighting conditions, backgrounds, resolutions, and perspectives within the image. These challenges **obfuscate the target within the image** where image complexity scales computational efforts exponentionally. The difference between predicting black and white images (single channel) versus multi-channel (RGB) images of different categories, is notable. \n",
    "\n",
    "A computational challenge in image classification is determining the location of the target within the background. The depth of this challenge increases exponentionally with image resolution and other image related attributes. Many modern models attempt to use Bounding-Box Regression, Region-Based CNN's, or RetinaNet. Which require extra steps resulting in extra mathematical operations.\n",
    "\n",
    "The paper `An image is worth 16x16 words` challenges this, and describes a strategy known as `picture patching` that splits an image into multiple, equal sized patches. *This approach is very much like the YOLO (You only look once) algorithm where it divides the image into equal size chunks and attempts to predict the bounding box based from each chunk.* These patches are then consumed by an algorithm, such as traditional machine learning, convolutional neural networks or attention retaining transformers (such as ViT or BiT). That utilize the individual patch information to determine the target and label the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Context\n",
    "\n",
    "Image classification is verbose, and requires acute attention to specific details. The verbosity of the problem expands with the complexity of the image, the more detailed the image, the harder it is to determine what the model is trying to predict.\n",
    "\n",
    "Image classification is important because it is a foundational step in other applications such as object detection, medical imaging or content filtering. It is the first step in machine learning that allows systems to interpret and understand visual data. It's applications span a wide range of industries, contributing to advancements in many technological fields and simplifying many image combing related processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Other Image Classification Approaches\n",
    "\n",
    "The limitations of image classification algorithms often revolve around a critical factor: speed. High computational complexity in determining the location of a target within an image introduces various constraints. The efficiency of target localization significantly influences the practical application of a specific algorithm.\n",
    "\n",
    "For instance, if speed is not a primary concern, and there's ample time available for processing, implementing a system based on R-CNN (Region-Based Convolutional Neural Networks) may offer high accuracy. This can be advantageous in applications such as identifying cancerous skin patches or spots, where precision counts.\n",
    "\n",
    "However, slower algorithms like R-CNN, Bounding-Box Regression, and Attention Mechanisms may not be suitable for systems requiring real-time predictions, such as self-driving vehicles or live object detection. In scenarios where immediate responses are crucial, faster models like YOLO (You Only Look Once) might be preferred due to their real-time capabilities.\n",
    "\n",
    "It's essential to strike a balance between speed and accuracy based on the specific requirements of the application, considering factors such as processing time, real-time constraints, and the nature of the target being detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "The solution implemented by the research paper `An image is worth 16x16 words` for classifying an image is called `patching`. Instead of scanning over a rasterization of pixels to determine the target, this paper suggests dividing the image into equal sized patches. \n",
    "\n",
    "This optimizes the process of determining the label of the image; where instead of using globalized retention over the entire rasterization, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
